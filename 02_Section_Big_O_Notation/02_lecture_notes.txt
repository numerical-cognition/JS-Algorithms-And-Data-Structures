*********************************************
------------Introducing Big O----------------
*********************************************

- Big O notation is a way to formalize fuzzy counting

- It allows us to talk formally about how the runtime of an algorithm grows as the inputs grow

We Say that an algorithm is O(f(n)) if the number of simple operations (the computer has to do) is eventually less than a constant times f(n), as n increases
------------------------------------------------------------------------
f(n) could be linear (f(n) = n)
f(n) could be quadratic (f(n) = n2)
f(n) could be constant (f(n) = 1)
f(n) could be something else...

-----------
| Example |
-----------

O(2n)  ---> O(n)
O(500) ---> O(1)
O(13n2)---> O(n2) [Sqared]

------------------
Big O Shorthands
------------------

1. Arithmetic operations are constant ---> O(1)
2. Variable assignment is constant ---> O(1)
3. Accessing elements in an array (by index) or object (by key) is constant ---> O(1)
4. In a loop, the complexity is the length of the loop times the complexity of whatever happens inside of the loop ---> O(n)




So far, we've been focusing on time complexity: 
- how can we analyze the runtime of an algorithm as the size of the inputs increases?

We can also use big O notation to analyze space complexity: 
- how much additional memory do we need to allocate in order to run the code in our algorithm?


Sometimes you'll hear the term auxiliary space complexity to refer to space required by the algorithm, not including space taken up by the inputs.

Unless otherwise noted, when we talk about space complexity, technically we'll be talking about auxiliary space complexity.
